---
title: "Issue 3"
date: 2021-11-22T16:14:14+01:00
showToc: true
TocOpen: true
draft: false
hidemeta: false
comments: false
ShowBreadCrumbs: false
ShowReadingTime: true
summary: |
  This week there's SARS-CoV-2 structures, protein computing agents, and sequence-structure embeddings.
cover:
    image: "img/3.png" # image path/url
    alt: "3" # alt text
    relative: false # when using page bundles set this to true
---


## [SCoV2-MD: a database for the dynamics of the SARS-CoV-2 proteome and variant impact predictions](https://doi.org/10.1093/nar/gkab977)
Need an overview over the structural landscape of SARS-CoV-2? The database presented in this paper might be for you.  Various models and experimental structures of protomers and oligomers in SARS-CoV-2 are presented together with a prediction of substrate and allosteric binding sites, protein-ligand docking, SARS-CoV-2 protein interactions with human proteins and impacts of mutations on stability mapped to their respective structures.

## [Two-input protein logic gate for computation in living cells](https://doi.org/10.1038/s41467-021-26937-x)
The authors design a "nano-computing agent", a protein kinase that functions as a 2-bit logic OR gate. The first input, rapamycin, activates kinase activity and the second input, blue light, inactivates kinase activity. Analogous to hardware engineering complexities, inactivation wasn't as fast as activation because of biological reasons. Similar setups could be applied to different kinds of proteins, giving us an arsenal of controllable protein agents for use in biomedicine and biotech.

## [Toward More General Embeddings for Protein Design: Harnessing Joint Representations of Sequence and Structure](https://doi.org/10.1101/2021.09.01.458592)
In [Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences](https://www.pnas.org/content/118/15/e2016239118), a transformer was trained on a huge dataset of sequences to embed proteins into a biologically meaningful learned embedding space. Here, the authors use this pre-trained model to generate sequence features, combine them with a graph representation of structures, and train a rotation and translation equivariant transformer to generate an embedding. This embedding performs better at mutation thermostability prediction likely because it's able to take into account sequentially-distant structurally-close influences. Of course this structural information can come from computationally predicted structures as well, following the trend in this post-AlphaFold era of replacing or augmenting sequence-based approaches with structure.


## Figure of the Week

{{< figure src="img/3_fotw.jpg" >}}
> Figure 1: Summary of the workflow, landscapes, and splits. (A) General FLIP workflow: choose landscapes and splits that match user needs, train models and make predictions on the test set, and then compare to baseline models. (B) We choose landscapes that cover different types of sequence diversity. The GB1 landscape focuses on simultaneous mutation of four epistatic sites with nearly complete coverage [[41](https://www.biorxiv.org/content/10.1101/2021.11.09.467890v1.full#ref-41)] (PDB ID: 2GI9 [[42](https://www.biorxiv.org/content/10.1101/2021.11.09.467890v1.full#ref-42)]). The AAV capsid protein landscape sparsely samples sequences with up to 28 mutations, including insertions and deletions, to the the binding interface [[43](https://www.biorxiv.org/content/10.1101/2021.11.09.467890v1.full#ref-43)] (PDB ID: 6IH9 [[44](https://www.biorxiv.org/content/10.1101/2021.11.09.467890v1.full#ref-44)]). The thermostability landscape [[45](https://www.biorxiv.org/content/10.1101/2021.11.09.467890v1.full#ref-45)] measures a property shared by proteins from multiple functional groups across different domains of life. (C). We also provide up to seven suggested data splits for each landscape, which are described in [Section 3](https://www.biorxiv.org/content/10.1101/2021.11.09.467890v1.full#sec-3).

**Source: [FLIP: Benchmark tasks in fitness landscape inference for proteins](https://doi.org/10.1101/2021.11.09.467890)**

## Some more
-  [Computational design of nanoscale rotational mechanics in _de novo_ protein assemblies](https://doi.org/10.1101/2021.11.11.468255)
-  [Science Forum: Nanoscape, a data-driven 3D real-time interactive virtual cell environment](https://doi.org/10.7554/eLife.64047)
-  [FLIP: Benchmark tasks in fitness landscape inference for proteins](https://doi.org/10.1101/2021.11.09.467890)
-  [Deep learning methods for designing proteins scaffolding functional sites](https://doi.org/10.1101/2021.11.10.468128)
-  [ParaFold: Paralleling AlphaFold for Large-Scale Predictions](https://arxiv.org/pdf/2111.06340.pdf)
-  [#COVIDisAirborne: AI-Enabled Multiscale Computational Microscopy of Delta SARS-CoV-2 in a Respiratory Aerosol](https://doi.org/10.1101/2021.11.12.468428)
-  [Computational Structural Genomics Unravels Common Folds and Novel Families in the Secretome of Fungal Phytopathogen _Magnaporthe oryzae_](https://doi.org/10.1094/MPMI-03-21-0071-R)
-  [Contrastive learning on protein embeddings enlightens midnight zone at lightning speed](https://doi.org/10.1101/2021.11.14.468528)
-  [Computational redesign of a fluorogen activating protein with Rosetta](https://doi.org/10.1371/journal.pcbi.1009555)
-  [Multi-Scale Representation Learning on Proteins](https://openreview.net/forum?id=-xEk43f_EO6)